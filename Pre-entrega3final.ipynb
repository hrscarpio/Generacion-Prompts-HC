{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9466f976-00b0-4ac3-8c26-8562aa04fa17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bbab6-e678-4d86-9cc7-4d2daf15563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias para interactuar con la API de OpenAI y manejar variables de entorno\n",
    "import openai\n",
    "import os\n",
    "import elevenlabs\n",
    "from elevenlabs import play\n",
    "from elevenlabs.client import ElevenLabs\n",
    "\n",
    "# Configurar la clave de la API de OpenAI utilizando una variable de entorno para mayor seguridad\n",
    "openai.api_key = \"Openai_ API_Key\"\n",
    "\n",
    "# Definir la función que utiliza la API de OpenAI para generar historias basadas en un contexto y un prompt específicos\n",
    "def generar_historia(context, prompt):\n",
    "    # Preparar ejemplos para el few-shot prompting, estructurando el diálogo para guiar a la IA\n",
    "    few_shot_examples = [\n",
    "        {\"role\": \"system\", \"content\": \"Contexto: \" + context},\n",
    "        {\"role\": \"user\", \"content\": \"Usuario: \" + prompt},\n",
    "        {\"role\": \"system\", \"content\": \"Sistema: ¿Puedes proporcionar más detalles sobre la historia?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Usuario: \" + prompt + \"\\nMás detalles sobre la historia.\"},\n",
    "    ]\n",
    "    \n",
    "    # Realizar la petición a la API para generar la historia, especificando el modelo y los parámetros de la solicitud\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=few_shot_examples,\n",
    "        temperature=1.2,\n",
    "        max_tokens=400\n",
    "    )\n",
    "    # Extraer el mensaje generado por la IA de la respuesta\n",
    "    message = response.choices[0]['message']\n",
    "    # Devolver el contenido del mensaje generado\n",
    "    return message['content']\n",
    "\n",
    "# Solicitar al usuario los inputs necesarios para generar la historia: contexto, personajes y detalles adicionales\n",
    "contexto = input(\"Escribe el contexto general de la historia:\")\n",
    "personajes = input(\"Describe tu personaje principal y secundarios:\")\n",
    "detalles_adicionales = input(\"Proporciona detalles adicionales sobre el entorno, conflictos, objetivos, etc. (opcional):\")\n",
    "\n",
    "# Validar que se hayan proporcionado los inputs mínimos requeridos para generar la historia\n",
    "if not contexto.strip() or not personajes.strip():\n",
    "    print(\"Debes proporcionar un contexto general de la historia y describir al menos un personaje principal.\")\n",
    "    exit()\n",
    "\n",
    "# Construir el prompt combinando los inputs del usuario, ajustándose a la necesidad de los detalles adicionales\n",
    "prompt = f\"{personajes}\\n{detalles_adicionales}\" if detalles_adicionales else personajes\n",
    "\n",
    "# Definir un prompt adicional para optimizar la historia, solicitando mejoras y detalles para enriquecer la narrativa\n",
    "# Prompt de optimización= mejora y detalla la siguiente historia, agregando elementos sorprendentes, giros inesperados y descripciones vívidas para cautivar al lector y sumergirlo en la narrativa:\n",
    "prompt_optimizacion = \"\"\"mejora y detalla la siguiente historia, agregando elementos sorprendentes, giros inesperados y descripciones vívidas para cautivar al lector y sumergirlo en la narrativa:\"\"\"\n",
    "\n",
    "# Generar la historia optimizada utilizando la función definida anteriormente y los prompts del usuario\n",
    "historia_optimizada = generar_historia(contexto, prompt_optimizacion)\n",
    "\n",
    "# Imprimir la historia optimizada\n",
    "print(\"Historia Generada (Optimizada):\")\n",
    "print(historia_optimizada)\n",
    "\n",
    "# Preparar dos prompts a partir de la historia optimizada para generar imágenes, dividiendo la historia en dos partes\n",
    "prompts_imagenes = [\n",
    "    historia_optimizada[:len(historia_optimizada)//2],  # Primera mitad de la historia\n",
    "    historia_optimizada[len(historia_optimizada)//2:],  # Segunda mitad de la historia\n",
    "]\n",
    "\n",
    "# Inicializar la lista para almacenar las URLs de las imágenes generadas\n",
    "def generar_imagenes(texto):\n",
    "    urls_imagenes = []\n",
    "    # Dividir el texto en segmentos de 1000 caracteres máximo\n",
    "    segmentos = [texto[i:i+1000] for i in range(0, len(texto), 1000)]\n",
    "    \n",
    "    for segmento in segmentos:\n",
    "        try:\n",
    "            response = openai.Image.create(\n",
    "                prompt=segmento,\n",
    "                n=1\n",
    "            )\n",
    "            # Asumiendo que la respuesta incluye al menos una imagen\n",
    "            url_imagen = response['data'][0]['url']\n",
    "            urls_imagenes.append(url_imagen)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al generar imagen para el segmento: {e}\")\n",
    "    \n",
    "    return urls_imagenes\n",
    "\n",
    "# Ejemplo de uso y otras partes del código omitidas por brevedad...\n",
    "\n",
    "# Generar y mostrar URLs de imágenes después de la generación de la historia optimizada\n",
    "urls_imagenes = generar_imagenes(historia_optimizada)\n",
    "print(\"URLs de las imágenes generadas:\")\n",
    "for url in urls_imagenes:\n",
    "    print(url)\n",
    "\n",
    "\n",
    "# integrar la generación de audio (Requiere implementación adicional)\n",
    "client = ElevenLabs(\n",
    "api_key = \"ElevenLabs API-Key\",\n",
    ")\n",
    "\n",
    "voice1 = elevenlabs.Voice(\n",
    "    voice_id = \"z9fAnlkpzviPz146aGWa\", #Voice of Glinda\n",
    "    settings = elevenlabs.VoiceSettings(\n",
    "        stability = 0.7,\n",
    "        similarity_boost = 0.75,\n",
    "        style=0.0,\n",
    "        use_speaker_boost=True\n",
    "    )\n",
    ")\n",
    "\n",
    "audio = client.generate(\n",
    "    text = historia_optimizada,\n",
    "    voice = voice1,\n",
    "    model = \"eleven_multilingual_v2\"\n",
    ")\n",
    "\n",
    "elevenlabs.play(audio)\n",
    "elevenlabs.save(audio, \"audio.mp3\")\n",
    "\n",
    "\n",
    "\n",
    "# (Opcional) Integración para generación de contenido de video\n",
    "def generar_video(historia, urls_imagenes):\n",
    "    # Esta función podría combinar las imágenes generadas y el audio en un video.\n",
    "    # La implementación específica dependerá de las herramientas y APIs disponibles.\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09dcb7-c69a-49a5-afbf-ae98535101bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
